{
 "cells": [
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Google Colab Environment Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google colab global var\n",
    "GOOGLE_COLAB = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GOOGLE_COLAB:\n",
    "    # Utilizar únicamente si se quiere descargar el repo completo\n",
    "    ! git clone --recursive https://german-milano:[passwd]@github.com/german-milano/mbd_thesis_private.git\n",
    "\n",
    "    # Para simplificar, muevo directorios y elimino lo necesario\n",
    "    ! mv ./mbd_thesis_private/project/agents ./\n",
    "    ! mv ./mbd_thesis_private/project/models ./\n",
    "    ! mv ./mbd_thesis_private/project/utils ./\n",
    "    ! rm -r mbd_thesis_private"
   ]
  },
  {
   "source": [
    "### Other Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_VIDEO = False"
   ]
  },
  {
   "source": [
    "#### Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite installation: use only if needed\n",
    "#! pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "#! apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "\n",
    "# Models\n",
    "from models.models import DQNModel, FQNModel\n",
    "\n",
    "# Agents\n",
    "from agents.dqn_agent import DQNAgent\n",
    "from agents.fqn_agent import FQNAgent\n",
    "\n",
    "# Utils\n",
    "from utils.utils_func import process_state, save_dataset, load_dataset\n",
    "from utils.visualization import plot_results, wrap_env, show_video\n",
    "\n",
    "# Gym\n",
    "import gym\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Misc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "source": [
    "### Deep Q-Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training global vars\n",
    "BUFFER_SIZE = 2000\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 1000\n",
    "MAX_STEPS = 200\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_RUNS = 1\n",
    "\n",
    "DATASET_ACTION_TYPE='random'"
   ]
  },
  {
   "source": [
    "De manera de evitar -en cierta medida- particularidades en las ejecuciones, se realizan ``NUM_RUNS`` entrenamientos. Para cada uno de ellos, se genera un dataset de experiencia y se agrega al dataset final que se utilizará para entrenar FQN."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arrays para los resultados finales\n",
    "rewards_mc_dqn, steps_mc_dqn = [], []\n",
    "agent_mc_dqn = None   # var for final agent\n",
    "\n",
    "# Modelo para el agente DQN\n",
    "model_dqn = None\n",
    "\n",
    "# Dataset para almacenar la experiencia del agente experto\n",
    "dataset = []\n",
    "\n",
    "# Lista para almacenar las trayectorias\n",
    "trajectories = []\n",
    "\n",
    "# Seed inicial\n",
    "num_seed = np.random.randint(0, 1000)\n",
    "\n",
    "for _run in range(NUM_RUNS):\n",
    "  # Print run\n",
    "  print(f\"\\nRun #{_run+1} | Seed: {num_seed}\")\n",
    "  print(\"********************************************************\")\n",
    "\n",
    "  # Creo el ambiente\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "  # Seed\n",
    "  env.seed(num_seed)\n",
    "  random.seed(num_seed)\n",
    "  np.random.seed(num_seed)\n",
    "  torch.manual_seed(num_seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "  # Creo el modelo\n",
    "  model_dqn = DQNModel(2, env.action_space.n)\n",
    "\n",
    "  # Creo el agente\n",
    "  agent_mc_dqn = DQNAgent(env, model_dqn, process_state, \n",
    "                          BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, \n",
    "                          epsilon_i=0.99, epsilon_f=0.1, epsilon_anneal_time=1000)\n",
    "\n",
    "  # Entreno al agente\n",
    "  rewards, steps_per_episode = agent_mc_dqn.train(NUM_EPISODES, MAX_STEPS)\n",
    "  \n",
    "  # Resultados\n",
    "  rewards_mc_dqn.append(rewards)\n",
    "  steps_mc_dqn.append(steps_per_episode)\n",
    "\n",
    "  # Genero dataset a partir de la red entrenada\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "  experience, traject = agent_mc_dqn.generate_dataset(env, action_type=DATASET_ACTION_TYPE, epsilon=.1, num_samples=NUM_SAMPLES, max_steps=MAX_STEPS)\n",
    "  dataset.extend(experience)\n",
    "  trajectories.extend(traject)\n",
    "\n",
    "  # Incremento el seed\n",
    "  num_seed += 1\n",
    "\n",
    "# Media de resultados por corrida\n",
    "rewards_mc_dqn = np.mean(rewards_mc_dqn, axis=0)\n",
    "steps_mc_dqn = np.mean(steps_mc_dqn, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \"suavizado\"\n",
    "plot_results(NUM_EPISODES, rewards_mc_dqn, steps_mc_dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE!!!\n",
    "\n",
    "experience, traject = agent_mc_dqn.generate_dataset(env, action_type=DATASET_ACTION_TYPE, epsilon=.1,num_samples=50000, max_steps=MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Check learning through video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_dqn.record_test_episode(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almaceno el dataset con transiciones\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "save_dataset(filename, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almaceno el dataset con trayectorias\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "save_dataset(filename, trajectories)"
   ]
  },
  {
   "source": [
    "### Neural Fitted Q-Iteration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Mountain Car"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levanto un dataset de samples obtenidos de un agente experto\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "dataset = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levanto un dataset de samples obtenidos de un agente experto\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "trajectories = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training vars\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 2000\n",
    "MAX_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING = False\n",
    "EARLY_STOPPING_PATIENCE = 1000\n",
    "\n",
    "# Vars for RIS metric\n",
    "N_ACTIONS = 3\n",
    "HORIZON = 200\n",
    "\n",
    "# Vars for testing cases\n",
    "IS_TEST = True\n",
    "TEST_RUN_TRIALS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FQN\n",
    "# Arrays para los resultados finales\n",
    "rewards_mc_fqn, steps_mc_fqn = [], []\n",
    "\n",
    "# Creo el ambiente\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Creo el modelo\n",
    "model_fqn = FQNModel(2, env.action_space.n)\n",
    "\n",
    "# Creo el agente\n",
    "agent_mc_fqn = FQNAgent(env, model_fqn, process_state, \n",
    "                        BATCH_SIZE, LEARNING_RATE, GAMMA,\n",
    "                        dataset, trajectories, \n",
    "                        N_ACTIONS, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entreno al agente\n",
    "rewards, steps_per_episode, ris_per_episode = agent_mc_fqn.train_from_dataset(NUM_EPISODES, is_test=IS_TEST, test_run_trials=TEST_RUN_TRIALS, early_stopping=EARLY_STOPPING, es_patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RIS\n",
    "plt.plot(range(1102), ris_per_episode)\n",
    "plt.title(\"Episode RIS\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_aux = [item for sublist in rewards for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rewards\n",
    "plt.plot(range(2000), rewards_aux)\n",
    "plt.title(\"Test Run Rewards\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Check learning through video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_fqn.record_test_episode(wrapped_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}