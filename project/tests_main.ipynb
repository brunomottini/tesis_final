{
 "cells": [
  {
   "source": [
    "# Main Tests\n",
    "### <font color='5E5D5D'> Descripción </font>\n",
    "\n",
    "<i><font color='C9614B'> En esta notebook se encuentra la mayor parte de las pruebas realizadas en lo que refiere a entrenamiento de agentes DQN y NFQ sin ventanas de rollout (Experimentos 1, 3 y 4). Tener en cuenta que la configuración que se presenta aquí, representa únicamente una de las evaluadas.</font></i><br>\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Configuración"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_VIDEO = False"
   ]
  },
  {
   "source": [
    "#### Librerías "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías del sistema que son prerequsito: descomentar estas líneas únicamente si se necesita su instalaciòn\n",
    "#! pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "#! apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "\n",
    "# Modelos\n",
    "from models.models import DQNModel, NFQModel\n",
    "\n",
    "# Agentes\n",
    "from agents.dqn_agent import DQNAgent\n",
    "from agents.nfq_agent import NFQAgent\n",
    "\n",
    "# Utilitarios\n",
    "from utils.utils_func import process_state, save_dataset, load_dataset\n",
    "from utils.visualization import plot_results, wrap_env, show_video\n",
    "\n",
    "# Gym\n",
    "import gym\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Misc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Gráficos\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests para los Experimentos 1, 3 y 4"
   ]
  },
  {
   "source": [
    "### Deep Q-Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Entrenamiento de agentes DQN, utilizando el ambiente ``MountainCar-v0``."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales para el entrenamiento\n",
    "BUFFER_SIZE = 2000\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 1000\n",
    "MAX_STEPS = 200\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Generación de datasets (RAND, ESA, EMA)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_RUNS = 1\n",
    "DATASET_ACTION_TYPE='greedy'"
   ]
  },
  {
   "source": [
    "De manera de evitar -en cierta medida- particularidades en las ejecuciones, se realizan ``NUM_RUNS`` entrenamientos. Para cada uno de ellos, se genera un dataset de experiencia y se agrega al dataset final que se utilizará para entrenar NFQ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arrays para los resultados finales\n",
    "rewards_mc_dqn, steps_mc_dqn = [], []\n",
    "agent_mc_dqn = None\n",
    "\n",
    "# Modelo para el agente DQN\n",
    "model_dqn = None\n",
    "\n",
    "# Dataset para almacenar la experiencia\n",
    "dataset = []\n",
    "\n",
    "# Lista para almacenar las trayectorias (para el cálculo de RIS)\n",
    "trajectories = []\n",
    "\n",
    "# Seed inicial (puede tomar cualquier valor deseado)\n",
    "num_seed = np.random.randint(0, 1000)\n",
    "\n",
    "for _run in range(NUM_RUNS):\n",
    "  # Info de la corrida\n",
    "  print(f\"\\nRun #{_run+1} | Seed: {num_seed}\")\n",
    "  print(\"********************************************************\")\n",
    "\n",
    "  # Ambiente\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "  # Configuraciòn del seed\n",
    "  env.seed(num_seed)\n",
    "  random.seed(num_seed)\n",
    "  np.random.seed(num_seed)\n",
    "  torch.manual_seed(num_seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "  # Creación del modelo\n",
    "  model_dqn = DQNModel(2, env.action_space.n)\n",
    "\n",
    "  # Creación del agente\n",
    "  agent_mc_dqn = DQNAgent(env, model_dqn, process_state, \n",
    "                          BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, \n",
    "                          epsilon_i=0.99, epsilon_f=0.1, epsilon_anneal_time=1000)\n",
    "\n",
    "  # Entrenamiento del agente\n",
    "  rewards, steps_per_episode = agent_mc_dqn.train(NUM_EPISODES, MAX_STEPS)\n",
    "  \n",
    "  # Guardar resultados\n",
    "  rewards_mc_dqn.append(rewards)\n",
    "  steps_mc_dqn.append(steps_per_episode)\n",
    "\n",
    "  # Generar dataset(s) utilizando agente(s) entrenado(s)\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "  experience, traject = agent_mc_dqn.generate_dataset(env, action_type=DATASET_ACTION_TYPE, epsilon=.1, num_samples=NUM_SAMPLES, max_steps=MAX_STEPS)\n",
    "  dataset.extend(experience)\n",
    "  trajectories.extend(traject)\n",
    "\n",
    "  # Incrementar el seed\n",
    "  num_seed += 1\n",
    "\n",
    "# Promedio de los resultados (por corrida)\n",
    "rewards_mc_dqn = np.mean(rewards_mc_dqn, axis=0)\n",
    "steps_mc_dqn = np.mean(steps_mc_dqn, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico \"suavizado\"\n",
    "plot_results(NUM_EPISODES, rewards_mc_dqn, steps_mc_dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Verificar aprendizaje a través del video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_dqn.record_test_episode(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataset de experiencia en formato pickle\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "save_dataset(filename, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataset de trayectorias en formato pickle\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "save_dataset(filename, trajectories)"
   ]
  },
  {
   "source": [
    "### Neural Fitted Q-Iteration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Entrenamiento de agentes NFQ, utilizando el ambiente ``MountainCar-v0``."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Mountain Car"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de experiencia desde archivo pickle\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "dataset = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset de trayectorias desde archivo pickle\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "trajectories = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales para el entrenamiento\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 2000\n",
    "MAX_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING = True\n",
    "EARLY_STOPPING_PATIENCE = 100\n",
    "\n",
    "# Variables para RIS\n",
    "N_ACTIONS = 3\n",
    "HORIZON = 200\n",
    "\n",
    "# Variables para el testing\n",
    "IS_TEST = True\n",
    "TEST_RUN_TRIALS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFQ\n",
    "# Listas para los resultados finales\n",
    "rewards_mc_nfq, steps_mc_nfq = [], []\n",
    "\n",
    "# Ambiente\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Creación del modelo\n",
    "model_nfq = NFQModel(2, env.action_space.n)\n",
    "\n",
    "# Creación del agente\n",
    "agent_mc_nfq = NFQAgent(env, model_nfq, process_state, \n",
    "                        BATCH_SIZE, LEARNING_RATE, GAMMA,\n",
    "                        dataset, trajectories, \n",
    "                        N_ACTIONS, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entrenamiento del agente\n",
    "rewards_mc_nfq, _, ris_mc_nfq = agent_mc_nfq.train_from_dataset(NUM_EPISODES, is_test=IS_TEST, test_run_trials=TEST_RUN_TRIALS, early_stopping=EARLY_STOPPING, es_patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de RIS\n",
    "# El eje 'x' tiene que tener dimensiones de (episode number + 1)\n",
    "plt.plot(range(102), ris_mc_nfq)\n",
    "plt.title(\"Episode RIS\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de rewards de test_run\n",
    "plt.plot(range(200), [item for sublist in rewards_mc_nfq for item in sublist])\n",
    "plt.title(\"Test Run Rewards\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Verificar aprendizaje a través del video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_nfq.record_test_episode(wrapped_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}