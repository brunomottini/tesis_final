{
 "cells": [
  {
   "source": [
    "# Main Tests\n",
    "### <font color='5E5D5D'> Descripción </font>\n",
    "\n",
    "<i><font color='C9614B'> En esta notebook se encuentra la mayor parte de las pruebas realizadas en lo que refiere a entrenamiento de agentes DQN y NFQ sin ventanas de rollout. Tener en cuenta que la configuración que se presenta aquí, representa únicamente una de las evaluadas.</font></i><br>\n",
    "\n",
    "***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAY_VIDEO = False"
   ]
  },
  {
   "source": [
    "#### Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite installation: use only if needed\n",
    "#! pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "#! apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "\n",
    "# Models\n",
    "from models.models import DQNModel, FQNModel\n",
    "\n",
    "# Agents\n",
    "from agents.dqn_agent import DQNAgent\n",
    "from agents.fqn_agent import FQNAgent\n",
    "\n",
    "# Utils\n",
    "from utils.utils_func import process_state, save_dataset, load_dataset\n",
    "from utils.visualization import plot_results, wrap_env, show_video\n",
    "\n",
    "# Gym\n",
    "import gym\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "\n",
    "# Misc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "source": [
    "### Deep Q-Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Entrenamiento de agentes DQN, utilizando el ambiente ``MountainCar-v0``."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training global vars\n",
    "BUFFER_SIZE = 2000\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 1000\n",
    "MAX_STEPS = 200\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Dataset generation (RAND, ESA, EMA)\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_RUNS = 1\n",
    "DATASET_ACTION_TYPE='greedy'"
   ]
  },
  {
   "source": [
    "De manera de evitar -en cierta medida- particularidades en las ejecuciones, se realizan ``NUM_RUNS`` entrenamientos. Para cada uno de ellos, se genera un dataset de experiencia y se agrega al dataset final que se utilizará para entrenar NFQ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arrays para los resultados finales\n",
    "rewards_mc_dqn, steps_mc_dqn = [], []\n",
    "agent_mc_dqn = None   # var for final agent\n",
    "\n",
    "# Model for DQN agent\n",
    "model_dqn = None\n",
    "\n",
    "# Dataset to store experience\n",
    "dataset = []\n",
    "\n",
    "# List to store trajectories (for RIS calculation)\n",
    "trajectories = []\n",
    "\n",
    "# Initial seed (could be set to any value)\n",
    "num_seed = np.random.randint(0, 1000)\n",
    "\n",
    "for _run in range(NUM_RUNS):\n",
    "  # Print run\n",
    "  print(f\"\\nRun #{_run+1} | Seed: {num_seed}\")\n",
    "  print(\"********************************************************\")\n",
    "\n",
    "  # Environment\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "  # Seed setup\n",
    "  env.seed(num_seed)\n",
    "  random.seed(num_seed)\n",
    "  np.random.seed(num_seed)\n",
    "  torch.manual_seed(num_seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  \n",
    "  # Model creation\n",
    "  model_dqn = DQNModel(2, env.action_space.n)\n",
    "\n",
    "  # Agent creation\n",
    "  agent_mc_dqn = DQNAgent(env, model_dqn, process_state, \n",
    "                          BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, \n",
    "                          epsilon_i=0.99, epsilon_f=0.1, epsilon_anneal_time=1000)\n",
    "\n",
    "  # Agent training\n",
    "  rewards, steps_per_episode = agent_mc_dqn.train(NUM_EPISODES, MAX_STEPS)\n",
    "  \n",
    "  # Save results\n",
    "  rewards_mc_dqn.append(rewards)\n",
    "  steps_mc_dqn.append(steps_per_episode)\n",
    "\n",
    "  # Using the trained agent(s), generate dataset\n",
    "  env = gym.make(\"MountainCar-v0\")\n",
    "  experience, traject = agent_mc_dqn.generate_dataset(env, action_type=DATASET_ACTION_TYPE, epsilon=.1, num_samples=NUM_SAMPLES, max_steps=MAX_STEPS)\n",
    "  dataset.extend(experience)\n",
    "  trajectories.extend(traject)\n",
    "\n",
    "  # Increment seed\n",
    "  num_seed += 1\n",
    "\n",
    "# Results averaging (per run)\n",
    "rewards_mc_dqn = np.mean(rewards_mc_dqn, axis=0)\n",
    "steps_mc_dqn = np.mean(steps_mc_dqn, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Smooth\" plot\n",
    "plot_results(NUM_EPISODES, rewards_mc_dqn, steps_mc_dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Check learning through video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_dqn.record_test_episode(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dataset with experience\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "save_dataset(filename, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle trajectories\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "save_dataset(filename, trajectories)"
   ]
  },
  {
   "source": [
    "### Neural Fitted Q-Iteration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Entrenamiento de agentes NFQ, utilizando el ambiente ``MountainCar-v0``."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Mountain Car"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with experience\n",
    "filename = 'datasets/dataset_sample.pkl'\n",
    "dataset = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trajectories\n",
    "filename = 'datasets/trajectories_sample.pkl'\n",
    "trajectories = load_dataset(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training vars\n",
    "GAMMA = 0.99\n",
    "NUM_EPISODES = 2000\n",
    "MAX_STEPS = 200\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING = True\n",
    "EARLY_STOPPING_PATIENCE = 100\n",
    "\n",
    "# Vars for RIS metric\n",
    "N_ACTIONS = 3\n",
    "HORIZON = 200\n",
    "\n",
    "# Vars for testing cases\n",
    "IS_TEST = True\n",
    "TEST_RUN_TRIALS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NFQ\n",
    "# Arrays para los resultados finales\n",
    "rewards_mc_nfq, steps_mc_nfq = [], []\n",
    "\n",
    "# Creo el ambiente\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "# Creo el modelo\n",
    "model_nfq = FQNModel(2, env.action_space.n)\n",
    "\n",
    "# Creo el agente\n",
    "agent_mc_nfq = FQNAgent(env, model_nfq, process_state, \n",
    "                        BATCH_SIZE, LEARNING_RATE, GAMMA,\n",
    "                        dataset, trajectories, \n",
    "                        N_ACTIONS, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entreno al agente\n",
    "rewards_mc_nfq, _, ris_mc_nfq = agent_mc_nfq.train_from_dataset(NUM_EPISODES, is_test=IS_TEST, test_run_trials=TEST_RUN_TRIALS, early_stopping=EARLY_STOPPING, es_patience=EARLY_STOPPING_PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIS plot\n",
    "# 'x' axis dim must be terminal episode number + 1\n",
    "plt.plot(range(102), ris_mc_nfq)\n",
    "plt.title(\"Episode RIS\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards plot\n",
    "plt.plot(range(200), [item for sublist in rewards_mc_nfq for item in sublist])\n",
    "plt.title(\"Test Run Rewards\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLAY_VIDEO:\n",
    "    # Check learning through video\n",
    "    wrapped_env = wrap_env(gym.make(\"MountainCar-v0\"))\n",
    "\n",
    "    agent_mc_nfq.record_test_episode(wrapped_env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}